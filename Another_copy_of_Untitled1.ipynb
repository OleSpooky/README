{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyNDdTpGCEd16Wtb9cp68k/4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OleSpooky/README/blob/main/Another_copy_of_Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2_33h9YkGQS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from scipy.special import expit\n",
        "\n",
        "# ==========================================\n",
        "# PART 1: VECTORIZED SIMULATOR (The Engine)\n",
        "# ==========================================\n",
        "\n",
        "def init_equilibrium_batch(N, M, rng):\n",
        "    return rng.integers(0, 2, size=(M, N), dtype=np.int8)\n",
        "\n",
        "def update_step_batch(X, c_arr, beta, theta_arr, rng):\n",
        "    M, N = X.shape\n",
        "    left = np.zeros_like(X)\n",
        "    right = np.zeros_like(X)\n",
        "    left[:, 1:] = X[:, :-1] * c_arr[:N-1]\n",
        "    right[:, :-1] = X[:, 1:] * c_arr[:N-1]\n",
        "    neighbor_sum = left + right\n",
        "    bias = beta * (neighbor_sum - theta_arr[None, :])\n",
        "    p1 = expit(bias)\n",
        "    U = rng.random(size=(M, N))\n",
        "    return (U < p1).astype(np.int8)\n",
        "\n",
        "def run_simulation_batch(N, c_arr, beta, theta_arr, M, T, source_j, master_seed=12345):\n",
        "    rng = np.random.default_rng(master_seed)\n",
        "    counts = np.zeros((T, N, 2, 2), dtype=np.int64)\n",
        "    X = init_equilibrium_batch(N, M, rng)\n",
        "    A = rng.integers(0, 2, size=M, dtype=np.int8)\n",
        "    X[:, source_j] = A\n",
        "\n",
        "    for t in range(T):\n",
        "        for a in (0, 1):\n",
        "            mask_a = (A == a)\n",
        "            if not np.any(mask_a): continue\n",
        "            sub = X[mask_a]\n",
        "            ones = np.sum(sub, axis=0)\n",
        "            zeros = sub.shape[0] - ones\n",
        "            counts[t, :, a, 1] += ones\n",
        "            counts[t, :, a, 0] += zeros\n",
        "        X = update_step_batch(X, c_arr, beta, theta_arr, rng)\n",
        "    return counts\n",
        "\n",
        "def compute_mi_from_counts(counts, M):\n",
        "    # counts shape: (T, N, 2, 2) -> (Time, Node, Source_Bit, State_Bit)\n",
        "    # Calculate Mutual Information I(A; X_i)\n",
        "    T, N, _, _ = counts.shape\n",
        "    I = np.zeros((T, N), dtype=float)\n",
        "    epsilon = 1e-12\n",
        "\n",
        "    for t in range(T):\n",
        "        for i in range(N):\n",
        "            # p(a, x) joint probability table\n",
        "            p_ax = counts[t, i].astype(float) / M\n",
        "            p_a = p_ax.sum(axis=1)  # Marginal p(source)\n",
        "            p_x = p_ax.sum(axis=0)  # Marginal p(node state)\n",
        "\n",
        "            mi = 0.0\n",
        "            for a_val in (0, 1):\n",
        "                for x_val in (0, 1):\n",
        "                    p = p_ax[a_val, x_val]\n",
        "                    if p > epsilon:\n",
        "                        denom = p_a[a_val] * p_x[x_val]\n",
        "                        if denom > epsilon:\n",
        "                            mi += p * np.log2(p / denom)\n",
        "            I[t, i] = mi\n",
        "    return I\n",
        "\n",
        "def compute_tau(I_matrix, threshold=1e-2):\n",
        "    # Find first time t where MI < threshold\n",
        "    T, N = I_matrix.shape\n",
        "    taus = np.zeros(N, dtype=int)\n",
        "    for i in range(N):\n",
        "        decayed = np.where(I_matrix[:, i] < threshold)[0]\n",
        "        if len(decayed) > 0:\n",
        "            taus[i] = decayed[0]\n",
        "        else:\n",
        "            taus[i] = T  # Never decayed\n",
        "    return taus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45ce3300"
      },
      "source": [
        "pip install numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 2: EXPERIMENT RUNNER (Data Generation)\n",
        "# ==========================================\n",
        "\n",
        "# Settings\n",
        "N = 21\n",
        "M = 2000        # Number of runs per batch\n",
        "T = 60          # Timesteps\n",
        "source_j = 10   # Source in the middle\n",
        "beta = 2.0\n",
        "theta_arr = np.ones(N) * 1.0\n",
        "folder = 'colab_results'\n",
        "\n",
        "# Ensure clean start\n",
        "if not os.path.exists(folder):\n",
        "    os.makedirs(folder)\n",
        "\n",
        "# Define 3 scenarios to demonstrate the contrast\n",
        "scenarios = [\n",
        "    (\"homogenous\", np.ones(N-1) * 1.0),             # Baseline\n",
        "    (\"p10.0_weak\",  np.ones(N-1) * 1.0),            # Will modify below\n",
        "    (\"p10.0_strong\", np.ones(N-1) * 1.0)            # Will modify below\n",
        "]\n",
        "\n",
        "# Apply modifications for pockets\n",
        "# Pocket at index 10 means couplings (9-10) and (10-11) are strong\n",
        "c_weak = np.ones(N-1) * 1.0\n",
        "c_weak[9:11] = 3.0  # Weak pocket\n",
        "scenarios[1] = (\"beta2.0_p10.0_weak\", c_weak)\n",
        "\n",
        "c_strong = np.ones(N-1) * 1.0\n",
        "c_strong[9:11] = 5.0 # Strong pocket\n",
        "scenarios[2] = (\"beta2.0_p10.0_strong\", c_strong)\n",
        "\n",
        "print(f\"Running {len(scenarios)} simulations...\")\n",
        "\n",
        "for name, c_profile in scenarios:\n",
        "    print(f\"  -> Simulating: {name}\")\n",
        "    counts = run_simulation_batch(N, c_profile, beta, theta_arr, M, T, source_j)\n",
        "    I = compute_mi_from_counts(counts, M)\n",
        "    taus = compute_tau(I, threshold=0.01)\n",
        "\n",
        "    # Save the I array for further analysis\n",
        "    np.save(os.path.join(folder, f'I_{name}.npy'), I)\n",
        "\n",
        "    # Save to CSV in the format expected by your analysis script\n",
        "    # Structure: node_index, tau\n",
        "    df = pd.DataFrame({\n",
        "        'node_index': np.arange(N),\n",
        "        'tau': taus\n",
        "    })\n",
        "    filename = os.path.join(folder, f'tau_{name}.csv')\n",
        "    df.to_csv(filename, index=False)\n",
        "\n",
        "print(\"Data generation complete.\\n\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "098zuvZ5klN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4966a263"
      },
      "source": [
        "# Paste and run: combine all tau CSVs into one DataFrame and show summary\n",
        "import os, glob, pandas as pd, numpy as np\n",
        "folder = 'colab_results'\n",
        "files = sorted(glob.glob(os.path.join(folder, 'tau_*.csv')))\n",
        "dfs = []\n",
        "for f in files:\n",
        "    cfg = os.path.basename(f).replace('tau_','').replace('.csv','')\n",
        "    df = pd.read_csv(f)\n",
        "    df['config'] = cfg\n",
        "    dfs.append(df)\n",
        "if dfs:\n",
        "    all_tau = pd.concat(dfs, ignore_index=True)\n",
        "    display(all_tau.head(40))\n",
        "    # compute mean tau inside/outside pocket if pocket indices are encoded in filename\n",
        "    def pocket_range_from_name(name):\n",
        "        # expects names like beta1.5_p10.0 or similar; fallback to center 10\n",
        "        try:\n",
        "            parts = name.split('_')\n",
        "            p = [s for s in parts if s.startswith('p')]\n",
        "            if p:\n",
        "                val = float(p[0][1:])\n",
        "                # approximate pocket center -> indices around center\n",
        "                return list(range(int(val)-3, int(val)+3))\n",
        "        except:\n",
        "            pass\n",
        "        return list(range(7,13))\n",
        "    summary = []\n",
        "    for cfg, g in all_tau.groupby('config'):\n",
        "        inside = pocket_range_from_name(cfg)\n",
        "        mean_inside = g[g['node_index'].isin(inside)]['tau'].mean()\n",
        "        mean_outside = g[~g['node_index'].isin(inside)]['tau'].mean()\n",
        "        summary.append((cfg, mean_inside, mean_outside, mean_inside-mean_outside))\n",
        "    summary_df = pd.DataFrame(summary, columns=['config','mean_tau_inside','mean_tau_outside','contrast'])\n",
        "    display(summary_df.sort_values('contrast', ascending=False))\n",
        "else:\n",
        "    print(\"No tau CSVs found in\", folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58036afd"
      },
      "source": [
        "# ==========================================\n",
        "# PART 3: YOUR ANALYSIS SCRIPT (Data Processing)\n",
        "# ==========================================\n",
        "\n",
        "print(\"--- RUNNING USER ANALYSIS ---\")\n",
        "\n",
        "files = sorted(glob.glob(os.path.join(folder, 'tau_*.csv')))\n",
        "dfs = []\n",
        "\n",
        "for f in files:\n",
        "    # Extract config name from filename\n",
        "    cfg = os.path.basename(f).replace('tau_', '').replace('.csv', '')\n",
        "    df = pd.read_csv(f)\n",
        "    df['config'] = cfg\n",
        "    dfs.append(df)\n",
        "\n",
        "if dfs:\n",
        "    all_tau = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    # Logic to identify pocket nodes based on filename\n",
        "    def pocket_range_from_name(name):\n",
        "        # Looks for 'p10.0' to set range around 10\n",
        "        try:\n",
        "            parts = name.split('_')\n",
        "            p = [s for s in parts if s.startswith('p')]\n",
        "            if p:\n",
        "                val = float(p[0][1:])\n",
        "                # Indices around center (e.g., 7 to 13)\n",
        "                return list(range(int(val)-3, int(val)+3))\n",
        "        except:\n",
        "            pass\n",
        "        return list(range(7, 13)) # Fallback\n",
        "\n",
        "    summary = []\n",
        "    for cfg, g in all_tau.groupby('config'):\n",
        "        inside_indices = pocket_range_from_name(cfg)\n",
        "\n",
        "        # Contrast: Mean Tau Inside vs Outside\n",
        "        mean_inside = g[g['node_index'].isin(inside_indices)]['tau'].mean()\n",
        "        mean_outside = g[~g['node_index'].isin(inside_indices)]['tau'].mean()\n",
        "\n",
        "        summary.append((cfg, mean_inside, mean_outside, mean_inside - mean_outside))\n",
        "\n",
        "    summary_df = pd.DataFrame(summary, columns=['config', 'tau_in', 'tau_out', 'contrast'])\n",
        "\n",
        "    # Display logic for Colab or Console\n",
        "    try:\n",
        "        from IPython.display import display\n",
        "        print(\"Summary Table:\")\n",
        "        display(all_tau.head(40))\n",
        "        display(summary_df.sort_values('contrast', ascending=False))\n",
        "    except ImportError:\n",
        "        print(all_tau.head(40))\n",
        "        print(summary_df.sort_values('contrast', ascending=False))\n",
        "else:\n",
        "    print(\"No tau CSVs found.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a46d694"
      },
      "source": [
        "# Paste and run: compute Σ_i I(A:i,t) from saved I arrays.\n",
        "import os, glob, numpy as np, matplotlib.pyplot as plt\n",
        "\n",
        "folder = 'colab_results'\n",
        "npy_files = sorted(glob.glob(os.path.join(folder, 'I_*.npy')))\n",
        "\n",
        "if npy_files:\n",
        "    plt.figure(figsize=(8,5))\n",
        "    for f in npy_files:\n",
        "        I = np.load(f)   # shape (T,N)\n",
        "        s = I.sum(axis=1)\n",
        "        label = os.path.basename(f).replace('I_', '').replace('.npy','')\n",
        "        plt.plot(s, label=label)\n",
        "    plt.xlabel('Timestep'); plt.ylabel('Sum I(A:i,t)'); plt.title('Total Mutual Information over Time'); plt.legend(); plt.grid(True); plt.show()\n",
        "else:\n",
        "    print(\"No I arrays (.npy) found in\", folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c729177c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bab60fba"
      },
      "source": [
        "After running the above cell and following the authentication steps, your Google Drive will be mounted at `/content/drive`. You can then access your files using paths like `/content/drive/My Drive/your_folder/your_file.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8f09928"
      },
      "source": [
        "# ==========================================\n",
        "# PART 2: EXPERIMENT RUNNER (Data Generation)\n",
        "# ==========================================\n",
        "\n",
        "# Settings\n",
        "N = 21\n",
        "M = 2000        # Number of runs per batch\n",
        "T = 60          # Timesteps\n",
        "source_j = 10   # Source in the middle\n",
        "beta = 2.0\n",
        "theta_arr = np.ones(N) * 1.0\n",
        "folder = 'colab_results'\n",
        "\n",
        "# Ensure clean start\n",
        "if not os.path.exists(folder):\n",
        "    os.makedirs(folder)\n",
        "\n",
        "# Define 3 scenarios to demonstrate the contrast\n",
        "scenarios = [\n",
        "    (\"homogenous\", np.ones(N-1) * 1.0),             # Baseline\n",
        "    (\"p10.0_weak\",  np.ones(N-1) * 1.0),            # Will modify below\n",
        "    (\"p10.0_strong\", np.ones(N-1) * 1.0)            # Will modify below\n",
        "]\n",
        "\n",
        "# Apply modifications for pockets\n",
        "# Pocket at index 10 means couplings (9-10) and (10-11) are strong\n",
        "c_weak = np.ones(N-1) * 1.0\n",
        "c_weak[9:11] = 3.0  # Weak pocket\n",
        "scenarios[1] = (\"beta2.0_p10.0_weak\", c_weak)\n",
        "\n",
        "c_strong = np.ones(N-1) * 1.0\n",
        "c_strong[9:11] = 5.0 # Strong pocket\n",
        "scenarios[2] = (\"beta2.0_p10.0_strong\", c_strong)\n",
        "\n",
        "print(f\"Running {len(scenarios)} simulations...\")\n",
        "\n",
        "for name, c_profile in scenarios:\n",
        "    print(f\"  -> Simulating: {name}\")\n",
        "    counts = run_simulation_batch(N, c_profile, beta, theta_arr, M, T, source_j)\n",
        "    I = compute_mi_from_counts(counts, M)\n",
        "    taus = compute_tau(I, threshold=0.01)\n",
        "\n",
        "    # Save the I array for further analysis\n",
        "    np.save(os.path.join(folder, f'I_{name}.npy'), I)\n",
        "\n",
        "    # Save to CSV in the format expected by your analysis script\n",
        "    # Structure: node_index, tau\n",
        "    df = pd.DataFrame({\n",
        "        'node_index': np.arange(N),\n",
        "        'tau': taus\n",
        "    })\n",
        "    filename = os.path.join(folder, f'tau_{name}.csv')\n",
        "    df.to_csv(filename, index=False)\n",
        "\n",
        "print(\"Data generation complete.\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 3: YOUR ANALYSIS SCRIPT (Data Processing)\n",
        "# ==========================================\n",
        "\n",
        "print(\"--- RUNNING USER ANALYSIS ---\")\n",
        "\n",
        "files = sorted(glob.glob(os.path.join(folder, 'tau_*.csv')))\n",
        "dfs = []\n",
        "\n",
        "for f in files:\n",
        "    # Extract config name from filename\n",
        "    cfg = os.path.basename(f).replace('tau_', '').replace('.csv', '')\n",
        "    df = pd.read_csv(f)\n",
        "    df['config'] = cfg\n",
        "    dfs.append(df)\n",
        "\n",
        "if dfs:\n",
        "    all_tau = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    # Logic to identify pocket nodes based on filename\n",
        "    def pocket_range_from_name(name):\n",
        "        # Looks for 'p10.0' to set range around 10\n",
        "        try:\n",
        "            parts = name.split('_')\n",
        "            p = [s for s in parts if s.startswith('p')]\n",
        "            if p:\n",
        "                val = float(p[0][1:])\n",
        "                # Indices around center (e.g., 7 to 13)\n",
        "                return list(range(int(val)-3, int(val)+3))\n",
        "        except:\n",
        "            pass\n",
        "        return list(range(7, 13)) # Fallback\n",
        "\n",
        "    summary = []\n",
        "    for cfg, g in all_tau.groupby('config'):\n",
        "        inside_indices = pocket_range_from_name(cfg)\n",
        "\n",
        "        # Contrast: Mean Tau Inside vs Outside\n",
        "        mean_inside = g[g['node_index'].isin(inside_indices)]['tau'].mean()\n",
        "        mean_outside = g[~g['node_index'].isin(inside_indices)]['tau'].mean()\n",
        "\n",
        "        summary.append((cfg, mean_inside, mean_outside, mean_inside - mean_outside))\n",
        "\n",
        "    summary_df = pd.DataFrame(summary, columns=['config', 'tau_in', 'tau_out', 'contrast'])\n",
        "\n",
        "    # Display logic for Colab or Console\n",
        "    try:\n",
        "        from IPython.display import display\n",
        "        print(\"Summary Table:\")\n",
        "        display(summary_df.sort_values('contrast', ascending=False))\n",
        "    except ImportError:\n",
        "        print(summary_df.sort_values('contrast', ascending=False))\n",
        "else:\n",
        "    print(\"No tau CSVs found.\")"
      ],
      "metadata": {
        "id": "glxpJek5klmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# If you are not in a Jupyter environment, ipywidgets will not work.\n",
        "from ipywidgets import interact, IntSlider, FloatSlider\n",
        "import time\n",
        "from scipy.special import expit\n",
        "\n",
        "# --- Core Simulation Functions (Vectorized Batch) ---\n",
        "\n",
        "def init_equilibrium_batch(N, M, rng):\n",
        "    return rng.integers(0, 2, size=(M, N), dtype=np.int8)\n",
        "\n",
        "def update_step_batch(X, c_arr, beta, theta_arr, rng):\n",
        "    M, N = X.shape\n",
        "    left = np.zeros_like(X)\n",
        "    right = np.zeros_like(X)\n",
        "    left[:, 1:] = X[:, :-1] * c_arr\n",
        "    right[:, :-1] = X[:, 1:] * c_arr\n",
        "    neighbor_sum = left + right\n",
        "    bias = beta * (neighbor_sum - theta_arr[None, :])\n",
        "    p1 = expit(bias)\n",
        "    U = rng.random(size=(M, N))\n",
        "    X_new = (U < p1).astype(np.int8)\n",
        "    return X_new\n",
        "\n",
        "def compute_mutual_information_from_counts(counts, M):\n",
        "    T, N, _, _ = counts.shape\n",
        "    I = np.zeros((T, N), dtype=float)\n",
        "    for t in range(T):\n",
        "        for i in range(N):\n",
        "            p_a_x = counts[t, i].astype(float) / M\n",
        "            p_a = p_a_x.sum(axis=1)\n",
        "            p_x = p_a_x.sum(axis=0)\n",
        "            mi = 0.0\n",
        "            for a in (0, 1):\n",
        "                for x in (0, 1):\n",
        "                    p = p_a_x[a, x]\n",
        "                    if p <= 0: continue\n",
        "                    denom = p_a[a] * p_x[x]\n",
        "                    if denom <= 0: continue\n",
        "                    mi += p * np.log2(p / denom)\n",
        "            I[t, i] = mi\n",
        "    return I\n",
        "\n",
        "def persistence_times(I_arr, eps):\n",
        "    T, N = I_arr.shape\n",
        "    tau = np.full(N, T, dtype=int)\n",
        "    for i in range(N):\n",
        "        below_indices = np.where(I_arr[:, i] < eps)[0]\n",
        "        if below_indices.size > 0:\n",
        "            tau[i] = below_indices[0]\n",
        "    return tau\n",
        "\n",
        "# --- Chunked Simulation Runner for Large M ---\n",
        "\n",
        "def run_simulation_chunked(N, c_arr, beta, theta_arr, M, T, source_j,\n",
        "                           master_seed=12345, chunk_size=500, continuous_source=False):\n",
        "\n",
        "    # Initialize main RNG for reproducibility and to generate seeds for chunks\n",
        "    main_rng = np.random.default_rng(master_seed)\n",
        "    total_counts = np.zeros((T, N, 2, 2), dtype=np.int64)\n",
        "\n",
        "    num_chunks = M // chunk_size + (1 if M % chunk_size != 0 else 0)\n",
        "\n",
        "    for chunk_idx in range(num_chunks):\n",
        "        current_chunk_size = min(chunk_size, M - chunk_idx * chunk_size)\n",
        "        if current_chunk_size == 0:\n",
        "            continue\n",
        "\n",
        "        # Generate unique seed for this chunk from the master RNG\n",
        "        chunk_seed = main_rng.integers(0, 2**32 - 1)\n",
        "        chunk_rng = np.random.default_rng(chunk_seed)\n",
        "\n",
        "        counts_chunk = np.zeros((T, N, 2, 2), dtype=np.int64)\n",
        "        X = init_equilibrium_batch(N, current_chunk_size, chunk_rng)\n",
        "        A = chunk_rng.integers(0, 2, size=current_chunk_size, dtype=np.int8)\n",
        "        X[:, source_j] = A\n",
        "\n",
        "        for t in range(T):\n",
        "            # accumulate counts across ensemble\n",
        "            for a in (0, 1):\n",
        "                mask_a = (A == a)\n",
        "                sub = X[mask_a]\n",
        "                if sub.size > 0:\n",
        "                    total_counts[t, :, a, 1] += np.sum(sub, axis=0)\n",
        "                    total_counts[t, :, a, 0] += sub.shape[0] - np.sum(sub, axis=0)\n",
        "\n",
        "            X = update_step_batch(X, c_arr, beta, theta_arr, chunk_rng)\n",
        "            if continuous_source:\n",
        "                 X[:, source_j] = A # Continuous clamping\n",
        "\n",
        "    return total_counts\n",
        "\n",
        "# --- Interactive Explorer Function ---\n",
        "\n",
        "def interactive_two(pocket_strength=10, beta=1.5):\n",
        "    N = 21\n",
        "    T = 60\n",
        "    source_j = 10\n",
        "    M = 1000            # keep small for interactivity; increase later for accuracy\n",
        "    chunk_size = 500\n",
        "    theta = 1.0\n",
        "    # continuous_source was missing from the call but defined in params\n",
        "    continuous_source = False\n",
        "    eps = 1e-3\n",
        "\n",
        "    # build pocket coupling centered at middle\n",
        "    c_pocket = np.ones(N-1)\n",
        "    mid = N//2; half = 3\n",
        "    # c_pocket indices cover nodes mid-half+1 to mid+half, linking mid-half to mid+half+1\n",
        "    c_pocket[mid-half:mid+half] = float(pocket_strength)\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    # Call the newly defined run_simulation_chunked function\n",
        "    counts = run_simulation_chunked(N, c_pocket, float(beta), np.ones(N)*theta,\n",
        "                                    M, T, source_j, master_seed=20251123,\n",
        "                                    chunk_size=chunk_size, continuous_source=continuous_source)\n",
        "    I = compute_mutual_information_from_counts(counts, M)\n",
        "    tau = persistence_times(I, eps=eps)\n",
        "    elapsed = time.perf_counter() - t0\n",
        "\n",
        "    # Plot global retained information\n",
        "    S = I.sum(axis=1)\n",
        "    plt.figure(figsize=(10,3))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.plot(S, '-o', markersize=3)\n",
        "    plt.xlabel('Timestep'); plt.ylabel('Sum I(A:i,t)')\n",
        "    plt.title('Global retained information')\n",
        "\n",
        "    # Heatmap\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(I.T, origin='lower', aspect='auto', cmap='viridis', extent=[0, T, 0, N])\n",
        "    plt.title(f'I heatmap p={pocket_strength} beta={beta}')\n",
        "    plt.xlabel('Timestep'); plt.ylabel('Node index')\n",
        "    plt.colorbar(shrink=0.6)\n",
        "\n",
        "    # Tau plot\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.plot(tau, marker='o')\n",
        "    plt.axvspan(mid-half, mid+half, color='orange', alpha=0.2) # Use correct indices for visualization\n",
        "    plt.xlabel('Node index'); plt.ylabel('Persistence time')\n",
        "    plt.title('tau per node')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    inside_idx = list(range(mid-half, mid+half))\n",
        "    outside_idx = [i for i in range(N) if i not in inside_idx]\n",
        "    mean_inside = np.nanmean(tau[inside_idx]) # Use nanmean just in case\n",
        "    mean_outside = np.nanmean(tau[outside_idx])\n",
        "    print(f\"pocket={pocket_strength} beta={beta}  mean_tau_inside={mean_inside:.4f}  mean_tau_outside={mean_outside:.4f}  elapsed={elapsed:.1f}s\")\n",
        "\n",
        "# Sliders: pocket 0–40, beta 0.2–4.0\n",
        "p_slider = IntSlider(value=10, min=0, max=40, step=1, description='pocket')\n",
        "b_slider = FloatSlider(value=1.5, min=0.2, max=4.0, step=0.1, description='beta')\n",
        "\n",
        "# This assumes you are running in a Jupyter environment (Notebook or Lab)\n",
        "if 'interact' in globals():\n",
        "    interact(interactive_two, pocket_strength=p_slider, beta=b_slider)\n",
        "else:\n",
        "    print(\"Run this script in a Jupyter environment to use the interactive sliders.\")\n",
        "    # If not interactive, run a single example:\n",
        "    interactive_two(pocket_strength=10, beta=1.5)"
      ],
      "metadata": {
        "id": "PNaIPY6Nw10J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Two‑slider interactive explorer for pocket_strength and beta\n",
        "# Requires the functions from Cells A-C already loaded in the notebook.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact, IntSlider, FloatSlider\n",
        "import time\n",
        "\n",
        "def interactive_two(pocket_strength=10, beta=1.5):\n",
        "    N = 21\n",
        "    T = 60\n",
        "    source_j = 10\n",
        "    M = 1000            # keep small for interactivity; increase later for accuracy\n",
        "    chunk_size = 500\n",
        "    theta = 1.0\n",
        "    continuous_source = False\n",
        "    eps = 1e-3\n",
        "\n",
        "    # build pocket coupling centered at middle\n",
        "    c_pocket = np.ones(N-1)\n",
        "    mid = N//2; half = 3\n",
        "    c_pocket[mid-half:mid+half] = float(pocket_strength)\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    counts = run_simulation_chunked(N, c_pocket, float(beta), np.ones(N)*theta,\n",
        "                                    M, T, source_j, master_seed=20251123,\n",
        "                                    chunk_size=chunk_size, continuous_source=continuous_source)\n",
        "    I = compute_mutual_information_from_counts(counts, M)\n",
        "    tau = persistence_times(I, eps=eps)\n",
        "    elapsed = time.perf_counter() - t0\n",
        "\n",
        "    # Plot global retained information\n",
        "    S = I.sum(axis=1)\n",
        "    plt.figure(figsize=(10,3))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.plot(S, '-o', markersize=3)\n",
        "    plt.xlabel('Timestep'); plt.ylabel('Sum I(A:i,t)')\n",
        "    plt.title('Global retained information')\n",
        "\n",
        "    # Heatmap\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(I.T, origin='lower', aspect='auto', cmap='viridis', extent=[0, T, 0, N])\n",
        "    plt.title(f'I heatmap p={pocket_strength} beta={beta}')\n",
        "    plt.xlabel('Timestep'); plt.ylabel('Node index')\n",
        "    plt.colorbar(shrink=0.6)\n",
        "\n",
        "    # Tau plot\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.plot(tau, marker='o')\n",
        "    plt.axvspan(mid-half, mid+half-1, color='orange', alpha=0.2)\n",
        "    plt.xlabel('Node index'); plt.ylabel('Persistence time')\n",
        "    plt.title('tau per node')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    inside_idx = list(range(mid-half, mid+half))\n",
        "    outside_idx = [i for i in range(N) if i not in inside_idx]\n",
        "    mean_inside = tau[inside_idx].mean()\n",
        "    mean_outside = tau[outside_idx].mean()\n",
        "    print(f\"pocket={pocket_strength} beta={beta}  mean_tau_inside={mean_inside:.4f}  mean_tau_outside={mean_outside:.4f}  elapsed={elapsed:.1f}s\")\n",
        "\n",
        "# Sliders: pocket 0–40, beta 0.2–4.0\n",
        "p_slider = IntSlider(value=10, min=0, max=40, step=1, description='pocket')\n",
        "b_slider = FloatSlider(value=1.5, min=0.2, max=4.0, step=0.1, description='beta')\n",
        "interact(interactive_two, pocket_strength=p_slider, beta=b_slider)"
      ],
      "metadata": {
        "id": "AbnliOBtxUaR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}